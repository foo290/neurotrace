{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"neurotrace","text":"<p>Work in progress</p> <p>Neurotrace is a Python library designed to facilitate the development of AI applications with a focus on memory management, message handling, and integration with various data storage systems. It provides a structured approach to managing conversational data, enabling developers to build intelligent systems that can remember context, emotions, and user interactions.</p>"},{"location":"#core-schema","title":"Core Schema","text":"<p>The <code>neurotrace.core.schema</code> module defines the fundamental data structures used throughout the project.</p>"},{"location":"#message","title":"Message","text":"<p>The core Message class represents a single message in the system:</p> <pre><code>from neurotrace.core.schema import Message, MessageMetadata, EmotionTag\n\nmessage = Message(\n    role=\"user\",           # Can be \"user\", \"ai\", or \"system\"\n    content=\"Hello!\",      # The message text content\n    metadata=MessageMetadata(\n        source=\"chat\",\n        emotions=EmotionTag(sentiment=\"positive\")\n    )\n)\n</code></pre> <p>Key features of Message: - Auto-generated UUID for each message - Automatic timestamp on creation - Type-safe role validation - Rich metadata support via MessageMetadata</p>"},{"location":"#message-components","title":"Message Components","text":""},{"location":"#emotiontag","title":"EmotionTag","text":"<p>Represents the emotional context of a message:</p> <pre><code>from neurotrace.core.schema import EmotionTag\n\nemotion = EmotionTag(\n    sentiment=\"positive\",  # Can be \"positive\", \"neutral\", or \"negative\"\n    intensity=0.8         # Optional float value indicating intensity\n)\n</code></pre>"},{"location":"#messagemetadata","title":"MessageMetadata","text":"<p>Contains additional information and context about a message:</p> <pre><code>from neurotrace.core.schema import MessageMetadata, EmotionTag\n\nmetadata = MessageMetadata(\n    token_count=150,                    # Number of tokens in the message\n    embedding=[0.1, 0.2, 0.3],         # Vector embedding for similarity search\n    source=\"chat\",                      # Source: \"chat\", \"web\", \"api\", or \"system\"\n    tags=[\"important\", \"follow-up\"],    # Custom tags\n    thread_id=\"thread_123\",            # Conversation thread identifier\n    user_id=\"user_456\",               # Associated user identifier\n    related_ids=[\"msg_789\"],          # Related message IDs\n    emotions=EmotionTag(sentiment=\"positive\"),  # Emotional context\n    compressed=False                   # Compression status\n)\n</code></pre> <p>Each field in MessageMetadata is optional and provides specific context: - <code>token_count</code>: Used for tracking token usage - <code>embedding</code>: Vector representation for similarity search - <code>source</code>: Indicates message origin - <code>tags</code>: Custom categorization - <code>thread_id</code>: Groups messages in conversations - <code>user_id</code>: Links messages to users - <code>related_ids</code>: Connects related messages - <code>emotions</code>: Captures emotional context - <code>compressed</code>: Indicates if content is compressed</p>"},{"location":"#adapters-module","title":"Adapters Module","text":"<p>The <code>neurotrace.core.adapters</code> module provides utilities for converting Message objects to and from various database and framework formats.</p>"},{"location":"#vector-database-adapter","title":"Vector Database Adapter","text":"<p>Convert messages to a format suitable for vector database storage:</p> <pre><code>from neurotrace.core.schema import Message, MessageMetadata\nfrom neurotrace.core.adapters.vector_db_adapter import to_vector_record\n\n# Create a message with an embedding\nmessage = Message(\n    content=\"Hello world\",\n    metadata=MessageMetadata(\n        embedding=[0.1, 0.2, 0.3],\n        tags=[\"greeting\"]\n    )\n)\n\n# Convert to vector DB format\nrecord = to_vector_record(message)\n# Results in: {\n#     \"id\": \"&lt;uuid&gt;\",\n#     \"text\": \"Hello world\",\n#     \"embedding\": [0.1, 0.2, 0.3],\n#     \"metadata\": {\"tags\": [\"greeting\"], ...}\n# }\n</code></pre>"},{"location":"#graph-database-adapter","title":"Graph Database Adapter","text":"<p>Convert messages to graph nodes and relationships:</p> <pre><code>from neurotrace.core.adapters.graph_db_adapter import to_graph_node, graph_edges_from_related_ids\nfrom neurotrace.core.schema import Message, MessageMetadata\n\n# Create a message with related IDs\nmessage = Message(\n    content=\"Follow-up response\",\n    metadata=MessageMetadata(\n        related_ids=[\"msg123\"],\n        tags=[\"follow-up\"]\n    )\n)\n\n# Convert to graph node\nnode = to_graph_node(message)\n# Results in: {\n#     \"id\": \"&lt;uuid&gt;\",\n#     \"labels\": [\"Message\"],\n#     \"properties\": {\n#         \"role\": \"user\",\n#         \"content\": \"Follow-up response\",\n#         \"tags\": [\"follow-up\"],\n#         ...\n#     }\n# }\n\n# Generate relationship edges\nedges = graph_edges_from_related_ids(message)\n# Results in: [{\n#     \"from\": \"&lt;current_msg_id&gt;\",\n#     \"to\": \"msg123\",\n#     \"type\": \"RELATED_TO\"\n# }]\n</code></pre>"},{"location":"#langchain-adapter","title":"LangChain Adapter","text":"<p>Convert between neurotrace Messages and LangChain message types:</p> <pre><code>from neurotrace.core.adapters.langchain_adapter import from_langchain_message\nfrom langchain_core.messages import HumanMessage\n\n# Convert from LangChain to neurotrace format\nlc_msg = HumanMessage(content=\"Hey there!\")\nmsg = from_langchain_message(lc_msg)\n# Results in Message(role=\"user\", content=\"Hey there!\")\n</code></pre> <p>Each adapter provides type-safe conversion between neurotrace's Message format and the target system's format, ensuring compatibility with various databases and frameworks.</p>"},{"location":"#memory-management","title":"Memory Management","text":"<p>The <code>neurotrace</code> system implements a sophisticated memory management system inspired by human memory architecture.</p>"},{"location":"#short-term-memory-stm","title":"Short Term Memory (STM)","text":"<p>Located in <code>neurotrace.core.hippocampus.stm</code>, the <code>ShortTermMemory</code> class provides temporary message storage with the following features:</p> <pre><code>from neurotrace.core.hippocampus.stm import ShortTermMemory\n\n# Initialize with token limit\nstm = ShortTermMemory(max_tokens=50)\n\n# Add messages\nstm.append(message)  # automatically handles token budget\n\n# Retrieve all current messages\nmessages = stm.get_messages()\n\n# Clear memory\nstm.clear()\n</code></pre> <p>Key features: - Token-based memory management - Automatic message eviction when token limit is exceeded - Timestamp-based message tracking - Efficient message retrieval</p>"},{"location":"#langchain-integration","title":"LangChain Integration","text":"<p>The <code>NeurotraceMemory</code> class provides seamless integration with LangChain:</p> <pre><code>from neurotrace.core.memory import NeurotraceMemory\n\nmemory = NeurotraceMemory(max_tokens=20)\n\n# Works with LangChain's memory interface\nmemory.save_context({\"input\": \"What's your name?\"}, {\"output\": \"I'm Neurotrace.\"})\nhistory = memory.load_memory_variables({})\n\n# Access chat history\nmessages = history[\"chat_history\"]  # Returns LangChain message format\n</code></pre> <p>Features: - Compatible with LangChain's memory system - Automatic conversion between Neurotrace and LangChain message formats - Preserves all metadata during conversions - Token budget management - Supports message source tracking</p>"},{"location":"#vector-database-integration","title":"Vector Database Integration","text":"<p>The vector database adapter now supports: - Automatic embedding storage and retrieval - Metadata preservation in vector records - Custom tagging for efficient retrieval - UUID-based message tracking</p> <p>Example usage: <pre><code>from neurotrace.core.adapters.vector_db_adapter import to_vector_record\n\nrecord = to_vector_record(message)\n# Creates a vector record with:\n# - Unique ID\n# - Message content\n# - Embeddings\n# - Complete metadata (tags, source, timestamps, etc.)\n</code></pre></p>"},{"location":"reference/documentation/core/constants/","title":"<code>neurotrace.core.constants</code>","text":""},{"location":"reference/documentation/core/constants/#neurotrace.core.constants","title":"<code>neurotrace.core.constants</code>","text":""},{"location":"reference/documentation/core/memory/","title":"<code>neurotrace.core.memory</code>","text":""},{"location":"reference/documentation/core/memory/#neurotrace.core.memory","title":"<code>neurotrace.core.memory</code>","text":""},{"location":"reference/documentation/core/memory/#neurotrace.core.memory.NeurotraceMemory","title":"<code>NeurotraceMemory</code>","text":"<p>               Bases: <code>BaseMemory</code></p> <p>LangChain-compatible memory wrapper that uses ShortTermMemory internally.</p> Source code in <code>neurotrace/core/memory.py</code> <pre><code>class NeurotraceMemory(BaseMemory):\n    \"\"\"\n    LangChain-compatible memory wrapper that uses ShortTermMemory internally.\n    \"\"\"\n    model_config = ConfigDict(\n        arbitrary_types_allowed=True,\n        extra=\"allow\",\n    )\n\n    def __init__(self, max_tokens: int = 2048, history: BaseChatMessageHistory = None, session_id: str = \"default\"):\n        super().__init__()\n        self.session_id = session_id\n        self._stm = ShortTermMemory(max_tokens=max_tokens)\n        self._ltm = LangchainHistoryAdapter(history, session_id=session_id) if history else None\n\n    @property\n    def memory_variables(self) -&gt; List[str]:\n        return [\"chat_history\"]\n\n    def load_memory_variables(self, inputs: Dict[str, Any]) -&gt; Dict[str, List[BaseMessage]]:\n        \"\"\"\n        Returns the memory in LangChain's message format.\n        \"\"\"\n        return {\"chat_history\": [msg.to_langchain_message() for msg in self._stm.get_messages()]}\n\n    def save_context(self, inputs: Dict[str, Any], outputs: Dict[str, Any]) -&gt; None:\n        \"\"\"\n        Receives inputs and outputs from LangChain agent and appends them as messages.\n        \"\"\"\n        user_input = inputs.get(\"input\") or \"\"\n        ai_output = outputs.get(\"output\") or \"\"\n\n        # Build Message objects\n        user_msg = Message(\n            id='boom',\n            role=Role.HUMAN,\n            content=user_input,\n            metadata=MessageMetadata(\n                session_id=self.session_id,\n            )\n        )\n        ai_msg = Message(\n            id='boom',\n            role=Role.AI,\n            content=ai_output,\n            metadata=MessageMetadata(\n                session_id=self.session_id,\n            )\n        )\n\n        # Save in short-term memory\n        self._stm.append(user_msg)\n        self._stm.append(ai_msg)\n\n        if self._ltm:\n            self._ltm.add_message(user_msg)\n            self._ltm.add_message(ai_msg)\n\n    def clear(self, delete_history: bool = False) -&gt; None:\n        self._stm.clear()\n        if self._ltm and delete_history:\n            self._ltm.clear()\n</code></pre>"},{"location":"reference/documentation/core/memory/#neurotrace.core.memory.NeurotraceMemory.load_memory_variables","title":"<code>load_memory_variables(inputs)</code>","text":"<p>Returns the memory in LangChain's message format.</p> Source code in <code>neurotrace/core/memory.py</code> <pre><code>def load_memory_variables(self, inputs: Dict[str, Any]) -&gt; Dict[str, List[BaseMessage]]:\n    \"\"\"\n    Returns the memory in LangChain's message format.\n    \"\"\"\n    return {\"chat_history\": [msg.to_langchain_message() for msg in self._stm.get_messages()]}\n</code></pre>"},{"location":"reference/documentation/core/memory/#neurotrace.core.memory.NeurotraceMemory.save_context","title":"<code>save_context(inputs, outputs)</code>","text":"<p>Receives inputs and outputs from LangChain agent and appends them as messages.</p> Source code in <code>neurotrace/core/memory.py</code> <pre><code>def save_context(self, inputs: Dict[str, Any], outputs: Dict[str, Any]) -&gt; None:\n    \"\"\"\n    Receives inputs and outputs from LangChain agent and appends them as messages.\n    \"\"\"\n    user_input = inputs.get(\"input\") or \"\"\n    ai_output = outputs.get(\"output\") or \"\"\n\n    # Build Message objects\n    user_msg = Message(\n        id='boom',\n        role=Role.HUMAN,\n        content=user_input,\n        metadata=MessageMetadata(\n            session_id=self.session_id,\n        )\n    )\n    ai_msg = Message(\n        id='boom',\n        role=Role.AI,\n        content=ai_output,\n        metadata=MessageMetadata(\n            session_id=self.session_id,\n        )\n    )\n\n    # Save in short-term memory\n    self._stm.append(user_msg)\n    self._stm.append(ai_msg)\n\n    if self._ltm:\n        self._ltm.add_message(user_msg)\n        self._ltm.add_message(ai_msg)\n</code></pre>"},{"location":"reference/documentation/core/orchestrator/","title":"<code>neurotrace.core.orchestrator</code>","text":""},{"location":"reference/documentation/core/orchestrator/#neurotrace.core.orchestrator","title":"<code>neurotrace.core.orchestrator</code>","text":"<p>Memory Orchestrator module for neurotrace.</p>"},{"location":"reference/documentation/core/retriever/","title":"<code>neurotrace.core.retriever</code>","text":""},{"location":"reference/documentation/core/retriever/#neurotrace.core.retriever","title":"<code>neurotrace.core.retriever</code>","text":"<p>Memory Retriever module for neurotrace.</p>"},{"location":"reference/documentation/core/schema/","title":"<code>neurotrace.core.schema</code>","text":""},{"location":"reference/documentation/core/schema/#neurotrace.core.schema","title":"<code>neurotrace.core.schema</code>","text":"<p>Schema definitions for neurotrace core components.</p> <p>This module defines the data structures used for managing neuromorphic memory components including messages, metadata, and emotion tags using Pydantic models.</p> Note <p>All models inherit from Pydantic BaseModel for data validation.</p>"},{"location":"reference/documentation/core/schema/#neurotrace.core.schema.EmotionTag","title":"<code>EmotionTag</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Represents the emotional context and intensity of a message.</p> <p>Attributes:</p> Name Type Description <code>sentiment</code> <code>Optional[Literal['positive', 'neutral', 'negative']]</code> <p>The emotional tone of the message. Defaults to None.</p> <code>intensity</code> <code>Optional[float]</code> <p>A value indicating the strength of the emotion. Defaults to None.</p> Source code in <code>neurotrace/core/schema.py</code> <pre><code>class EmotionTag(BaseModel):\n    \"\"\"Represents the emotional context and intensity of a message.\n\n    Attributes:\n        sentiment (Optional[Literal[\"positive\", \"neutral\", \"negative\"]]): The emotional\n            tone of the message. Defaults to None.\n        intensity (Optional[float]): A value indicating the strength of the emotion.\n            Defaults to None.\n    \"\"\"\n\n    sentiment: Optional[Literal[\"positive\", \"neutral\", \"negative\"]] = None\n    intensity: Optional[float] = None\n</code></pre>"},{"location":"reference/documentation/core/schema/#neurotrace.core.schema.Message","title":"<code>Message</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Message represents a single communication in the system. It includes the sender's role, content, timestamp, and metadata. Each message has a unique identifier generated as a UUID.</p> <p>Example Representation: {     \"id\": \"\",                    # unique message ID     \"role\": \"user\" | \"ai\" | \"system\",           # sender role     \"content\": \"string\",                        # message text     \"timestamp\": \"ISO 8601\",                    # message time (UTC)     \"metadata\": {         \"token_count\": 32,                      # optional, for budgeting/compression         \"embedding\": [...],                     # vector representation (optional in-memory or precomputed)         \"source\": \"chat\" | \"web\" | \"api\",       # source of message         \"tags\": [\"finance\", \"personal\"],        # custom tags for search         \"thread_id\": \"conversation_XYZ\",        # optional thread/conversation tracking         \"user_id\": \"abc123\",                    # to associate memory across sessions         \"related_ids\": [\"msg_id_1\", \"msg_id_2\"],# links to other related messages (graph edge)         \"emotions\": {\"sentiment\": \"positive\", \"intensity\": 0.85},  # optional emotion tagging         \"compressed\": False                     # for summarization/compression tracking         \"session_id\": \"default\"                # session identifier for context     } } Source code in <code>neurotrace/core/schema.py</code> <pre><code>class Message(BaseModel):\n    \"\"\"\n    Message represents a single communication in the system.\n    It includes the sender's role, content, timestamp, and metadata.\n    Each message has a unique identifier generated as a UUID.\n\n    Example Representation:\n    {\n        \"id\": \"&lt;uuid4 or hash&gt;\",                    # unique message ID\n        \"role\": \"user\" | \"ai\" | \"system\",           # sender role\n        \"content\": \"string\",                        # message text\n        \"timestamp\": \"ISO 8601\",                    # message time (UTC)\n        \"metadata\": {\n            \"token_count\": 32,                      # optional, for budgeting/compression\n            \"embedding\": [...],                     # vector representation (optional in-memory or precomputed)\n            \"source\": \"chat\" | \"web\" | \"api\",       # source of message\n            \"tags\": [\"finance\", \"personal\"],        # custom tags for search\n            \"thread_id\": \"conversation_XYZ\",        # optional thread/conversation tracking\n            \"user_id\": \"abc123\",                    # to associate memory across sessions\n            \"related_ids\": [\"msg_id_1\", \"msg_id_2\"],# links to other related messages (graph edge)\n            \"emotions\": {\"sentiment\": \"positive\", \"intensity\": 0.85},  # optional emotion tagging\n            \"compressed\": False                     # for summarization/compression tracking\n            \"session_id\": \"default\"                # session identifier for context\n        }\n    }\n    \"\"\"\n\n    id: str = Field(default_factory=lambda: str(uuid.uuid4()))\n    role: str\n    content: str\n    timestamp: datetime = Field(default_factory=lambda: datetime.now(UTC))\n    metadata: MessageMetadata = Field(default_factory=MessageMetadata)\n\n    def estimated_token_length(self) -&gt; int:\n        \"\"\"Estimates the number of tokens in the message content.\n\n        Returns:\n            int: The estimated token count, either from metadata or word-based count.\n\n        Note:\n            Currently uses a simple word-splitting approach if token_count is not set\n            in metadata. TODO: Implement a more accurate token counting method.\n        \"\"\"\n        # todo: Implement a more accurate token counting method\n        return self.metadata.token_count or len(self.content.split())\n\n    def to_langchain_message(self) -&gt; Union[HumanMessage, AIMessage]:\n        \"\"\"Converts this Message to a LangChain compatible format.\n\n        Returns:\n            Union[HumanMessage, AIMessage]: A LangChain message object based on the role.\n\n        Raises:\n            ValueError: If the role is neither 'human' nor 'ai'.\n        \"\"\"\n        if Role.from_string(self.role) is Role.HUMAN:\n            return self.to_human_message()\n        elif Role.from_string(self.role) is Role.AI:\n            return self.to_ai_message()\n        else:\n            raise ValueError(f\"Unsupported role: {self.role}. Use 'human' or 'ai'.\")\n\n    def to_human_message(self) -&gt; HumanMessage:\n        \"\"\"Converts this Message to a LangChain HumanMessage format.\n\n        Returns:\n            HumanMessage: A LangChain HumanMessage with the message content and metadata.\n        \"\"\"\n        return HumanMessage(\n            id=self.id, content=self.content, additional_kwargs={\"id\": self.id, \"metadata\": self.metadata.model_dump()}\n        )\n\n    def to_ai_message(self) -&gt; AIMessage:\n        \"\"\"Converts this Message to a LangChain AIMessage format.\n\n        Returns:\n            AIMessage: A LangChain AIMessage with the message content and metadata.\n        \"\"\"\n        return AIMessage(\n            id=self.id, content=self.content, additional_kwargs={\"id\": self.id, \"metadata\": self.metadata.model_dump()}\n        )\n\n    def __eq__(self, other):\n        \"\"\"Checks equality between two Message objects.\n\n        Args:\n            other: Another object to compare with.\n\n        Returns:\n            bool: True if the messages have the same role, content, and metadata\n                (excluding id), False otherwise.\n        \"\"\"\n        if not isinstance(other, Message):\n            return False\n\n        # not comparing id\n        return self.role == other.role and self.content == other.content and self.metadata == other.metadata\n</code></pre>"},{"location":"reference/documentation/core/schema/#neurotrace.core.schema.Message.__eq__","title":"<code>__eq__(other)</code>","text":"<p>Checks equality between two Message objects.</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <p>Another object to compare with.</p> required <p>Returns:</p> Name Type Description <code>bool</code> <p>True if the messages have the same role, content, and metadata (excluding id), False otherwise.</p> Source code in <code>neurotrace/core/schema.py</code> <pre><code>def __eq__(self, other):\n    \"\"\"Checks equality between two Message objects.\n\n    Args:\n        other: Another object to compare with.\n\n    Returns:\n        bool: True if the messages have the same role, content, and metadata\n            (excluding id), False otherwise.\n    \"\"\"\n    if not isinstance(other, Message):\n        return False\n\n    # not comparing id\n    return self.role == other.role and self.content == other.content and self.metadata == other.metadata\n</code></pre>"},{"location":"reference/documentation/core/schema/#neurotrace.core.schema.Message.estimated_token_length","title":"<code>estimated_token_length()</code>","text":"<p>Estimates the number of tokens in the message content.</p> <p>Returns:</p> Name Type Description <code>int</code> <code>int</code> <p>The estimated token count, either from metadata or word-based count.</p> Note <p>Currently uses a simple word-splitting approach if token_count is not set in metadata. TODO: Implement a more accurate token counting method.</p> Source code in <code>neurotrace/core/schema.py</code> <pre><code>def estimated_token_length(self) -&gt; int:\n    \"\"\"Estimates the number of tokens in the message content.\n\n    Returns:\n        int: The estimated token count, either from metadata or word-based count.\n\n    Note:\n        Currently uses a simple word-splitting approach if token_count is not set\n        in metadata. TODO: Implement a more accurate token counting method.\n    \"\"\"\n    # todo: Implement a more accurate token counting method\n    return self.metadata.token_count or len(self.content.split())\n</code></pre>"},{"location":"reference/documentation/core/schema/#neurotrace.core.schema.Message.to_ai_message","title":"<code>to_ai_message()</code>","text":"<p>Converts this Message to a LangChain AIMessage format.</p> <p>Returns:</p> Name Type Description <code>AIMessage</code> <code>AIMessage</code> <p>A LangChain AIMessage with the message content and metadata.</p> Source code in <code>neurotrace/core/schema.py</code> <pre><code>def to_ai_message(self) -&gt; AIMessage:\n    \"\"\"Converts this Message to a LangChain AIMessage format.\n\n    Returns:\n        AIMessage: A LangChain AIMessage with the message content and metadata.\n    \"\"\"\n    return AIMessage(\n        id=self.id, content=self.content, additional_kwargs={\"id\": self.id, \"metadata\": self.metadata.model_dump()}\n    )\n</code></pre>"},{"location":"reference/documentation/core/schema/#neurotrace.core.schema.Message.to_human_message","title":"<code>to_human_message()</code>","text":"<p>Converts this Message to a LangChain HumanMessage format.</p> <p>Returns:</p> Name Type Description <code>HumanMessage</code> <code>HumanMessage</code> <p>A LangChain HumanMessage with the message content and metadata.</p> Source code in <code>neurotrace/core/schema.py</code> <pre><code>def to_human_message(self) -&gt; HumanMessage:\n    \"\"\"Converts this Message to a LangChain HumanMessage format.\n\n    Returns:\n        HumanMessage: A LangChain HumanMessage with the message content and metadata.\n    \"\"\"\n    return HumanMessage(\n        id=self.id, content=self.content, additional_kwargs={\"id\": self.id, \"metadata\": self.metadata.model_dump()}\n    )\n</code></pre>"},{"location":"reference/documentation/core/schema/#neurotrace.core.schema.Message.to_langchain_message","title":"<code>to_langchain_message()</code>","text":"<p>Converts this Message to a LangChain compatible format.</p> <p>Returns:</p> Type Description <code>Union[HumanMessage, AIMessage]</code> <p>Union[HumanMessage, AIMessage]: A LangChain message object based on the role.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the role is neither 'human' nor 'ai'.</p> Source code in <code>neurotrace/core/schema.py</code> <pre><code>def to_langchain_message(self) -&gt; Union[HumanMessage, AIMessage]:\n    \"\"\"Converts this Message to a LangChain compatible format.\n\n    Returns:\n        Union[HumanMessage, AIMessage]: A LangChain message object based on the role.\n\n    Raises:\n        ValueError: If the role is neither 'human' nor 'ai'.\n    \"\"\"\n    if Role.from_string(self.role) is Role.HUMAN:\n        return self.to_human_message()\n    elif Role.from_string(self.role) is Role.AI:\n        return self.to_ai_message()\n    else:\n        raise ValueError(f\"Unsupported role: {self.role}. Use 'human' or 'ai'.\")\n</code></pre>"},{"location":"reference/documentation/core/schema/#neurotrace.core.schema.MessageMetadata","title":"<code>MessageMetadata</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Contains additional contextual information about a message.</p> <p>Attributes:</p> Name Type Description <code>token_count</code> <code>Optional[int]</code> <p>Number of tokens in the associated message.</p> <code>embedding</code> <code>Optional[List[float]]</code> <p>Vector representation of the message content.</p> <code>source</code> <code>Optional[Literal['chat', 'web', 'api', 'system']]</code> <p>Origin of the message. Defaults to \"chat\".</p> <code>tags</code> <code>Optional[List[str]]</code> <p>List of categorical tags. Defaults to empty list.</p> <code>thread_id</code> <code>Optional[str]</code> <p>Unique identifier for the conversation thread.</p> <code>user_id</code> <code>Optional[str]</code> <p>Identifier for the message author.</p> <code>related_ids</code> <code>Optional[List[str]]</code> <p>References to related message IDs.</p> <code>emotions</code> <code>Optional[EmotionTag]</code> <p>Emotional analysis of the message.</p> <code>compressed</code> <code>Optional[bool]</code> <p>Whether the message content is compressed. Defaults to False.</p> <code>session_id</code> <code>Optional[str]</code> <p>Current session identifier. Defaults to 'default'.</p> Source code in <code>neurotrace/core/schema.py</code> <pre><code>class MessageMetadata(BaseModel):\n    \"\"\"Contains additional contextual information about a message.\n\n    Attributes:\n        token_count (Optional[int]): Number of tokens in the associated message.\n        embedding (Optional[List[float]]): Vector representation of the message content.\n        source (Optional[Literal[\"chat\", \"web\", \"api\", \"system\"]]): Origin of the message.\n            Defaults to \"chat\".\n        tags (Optional[List[str]]): List of categorical tags. Defaults to empty list.\n        thread_id (Optional[str]): Unique identifier for the conversation thread.\n        user_id (Optional[str]): Identifier for the message author.\n        related_ids (Optional[List[str]]): References to related message IDs.\n        emotions (Optional[EmotionTag]): Emotional analysis of the message.\n        compressed (Optional[bool]): Whether the message content is compressed.\n            Defaults to False.\n        session_id (Optional[str]): Current session identifier. Defaults to 'default'.\n    \"\"\"\n\n    token_count: Optional[int] = None\n    embedding: Optional[List[float]] = None\n    source: Optional[Literal[\"chat\", \"web\", \"api\", \"system\"]] = \"chat\"\n    tags: Optional[List[str]] = []\n    thread_id: Optional[str] = None\n    user_id: Optional[str] = None\n    related_ids: Optional[List[str]] = []\n    emotions: Optional[EmotionTag] = None\n    compressed: Optional[bool] = False\n    session_id: Optional[str] = \"default\"\n</code></pre>"},{"location":"reference/documentation/core/adapters/graph_db_adapter/","title":"<code>neurotrace.core.adapters.graph_db_adapter</code>","text":""},{"location":"reference/documentation/core/adapters/graph_db_adapter/#neurotrace.core.adapters.graph_db_adapter","title":"<code>neurotrace.core.adapters.graph_db_adapter</code>","text":"<p>Graph Database Adapter Module.</p> <p>This module provides adapter functions for converting neurotrace Message objects into graph database compatible formats. It handles the transformation of messages into graph nodes and relationship edges, suitable for graph database storage and querying.</p>"},{"location":"reference/documentation/core/adapters/graph_db_adapter/#neurotrace.core.adapters.graph_db_adapter.graph_edges_from_related_ids","title":"<code>graph_edges_from_related_ids(msg)</code>","text":"<p>Generate graph relationship edges from a message's related IDs.</p> <p>This function creates relationship edges between the given message and its related messages, as specified in the message's metadata. Each relationship is of type \"RELATED_TO\".</p> <p>Parameters:</p> Name Type Description Default <code>msg</code> <code>Message</code> <p>The Message object to generate relationship edges for.</p> required <p>Returns:</p> Type Description <code>List[Dict[str, str]]</code> <p>List[Dict[str, str]]: A list of edge dictionaries, each containing: - from: The source message ID (current message) - to: The target message ID (related message) - type: The relationship type (\"RELATED_TO\")</p> Example <p>msg = Message(id=\"123\", metadata=MessageMetadata(related_ids=[\"456\"])) edges = graph_edges_from_related_ids(msg) print(edges[0])  # {\"from\": \"123\", \"to\": \"456\", \"type\": \"RELATED_TO\"}</p> Source code in <code>neurotrace/core/adapters/graph_db_adapter.py</code> <pre><code>def graph_edges_from_related_ids(msg: \"Message\") -&gt; List[Dict[str, str]]:\n    \"\"\"\n    Generate graph relationship edges from a message's related IDs.\n\n    This function creates relationship edges between the given message and its\n    related messages, as specified in the message's metadata. Each relationship\n    is of type \"RELATED_TO\".\n\n    Args:\n        msg (Message): The Message object to generate relationship edges for.\n\n    Returns:\n        List[Dict[str, str]]: A list of edge dictionaries, each containing:\n            - from: The source message ID (current message)\n            - to: The target message ID (related message)\n            - type: The relationship type (\"RELATED_TO\")\n\n    Example:\n        &gt;&gt;&gt; msg = Message(id=\"123\", metadata=MessageMetadata(related_ids=[\"456\"]))\n        &gt;&gt;&gt; edges = graph_edges_from_related_ids(msg)\n        &gt;&gt;&gt; print(edges[0])  # {\"from\": \"123\", \"to\": \"456\", \"type\": \"RELATED_TO\"}\n    \"\"\"\n    return [{\"from\": msg.id, \"to\": rid, \"type\": \"RELATED_TO\"} for rid in msg.metadata.related_ids or []]\n</code></pre>"},{"location":"reference/documentation/core/adapters/graph_db_adapter/#neurotrace.core.adapters.graph_db_adapter.to_graph_node","title":"<code>to_graph_node(msg)</code>","text":"<p>Convert a Message object to a graph database node format.</p> <p>This function transforms a neurotrace Message into a dictionary format suitable for creating nodes in a graph database. It includes the message's core properties and flattens metadata into the node properties.</p> <p>Parameters:</p> Name Type Description Default <code>msg</code> <code>Message</code> <p>The Message object to convert into a graph node.</p> required <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Dict[str, Any]: A dictionary containing: - id: The unique identifier for the node - labels: List of node labels ([\"Message\"]) - properties: Dict containing:     - role: The message role (user/ai/system)     - content: The message text content     - timestamp: ISO formatted timestamp     - Additional properties from message metadata</p> Example <p>msg = Message(id=\"123\", content=\"Hello\", role=\"user\") node = to_graph_node(msg) print(node[\"labels\"])  # [\"Message\"] print(node[\"properties\"][\"role\"])  # \"user\"</p> Source code in <code>neurotrace/core/adapters/graph_db_adapter.py</code> <pre><code>def to_graph_node(msg: \"Message\") -&gt; Dict[str, Any]:\n    \"\"\"\n    Convert a Message object to a graph database node format.\n\n    This function transforms a neurotrace Message into a dictionary format\n    suitable for creating nodes in a graph database. It includes the message's\n    core properties and flattens metadata into the node properties.\n\n    Args:\n        msg (Message): The Message object to convert into a graph node.\n\n    Returns:\n        Dict[str, Any]: A dictionary containing:\n            - id: The unique identifier for the node\n            - labels: List of node labels ([\"Message\"])\n            - properties: Dict containing:\n                - role: The message role (user/ai/system)\n                - content: The message text content\n                - timestamp: ISO formatted timestamp\n                - Additional properties from message metadata\n\n    Example:\n        &gt;&gt;&gt; msg = Message(id=\"123\", content=\"Hello\", role=\"user\")\n        &gt;&gt;&gt; node = to_graph_node(msg)\n        &gt;&gt;&gt; print(node[\"labels\"])  # [\"Message\"]\n        &gt;&gt;&gt; print(node[\"properties\"][\"role\"])  # \"user\"\n    \"\"\"\n    return {\n        \"id\": msg.id,\n        \"labels\": [\"Message\"],\n        \"properties\": {\n            \"role\": msg.role,\n            \"content\": msg.content,\n            \"timestamp\": msg.timestamp.isoformat(),\n            **msg.metadata.model_dump()\n        }\n    }\n</code></pre>"},{"location":"reference/documentation/core/adapters/langchain_adapter/","title":"<code>neurotrace.core.adapters.langchain_adapter</code>","text":""},{"location":"reference/documentation/core/adapters/langchain_adapter/#neurotrace.core.adapters.langchain_adapter","title":"<code>neurotrace.core.adapters.langchain_adapter</code>","text":"<p>LangChain Adapter Module.</p> <p>This module provides adapter functions for converting between neurotrace's internal Message format and LangChain's message formats. It handles bidirectional conversion between neurotrace Messages and LangChain's HumanMessage/AIMessage types.</p>"},{"location":"reference/documentation/core/adapters/langchain_adapter/#neurotrace.core.adapters.langchain_adapter.from_langchain_message","title":"<code>from_langchain_message(msg, role=None)</code>","text":"<p>Convert a LangChain message to a neurotrace Message.</p> <p>This function transforms a LangChain message into neurotrace's Message format, with automatic role detection based on the message type or an optional explicit role override.</p> <p>Parameters:</p> Name Type Description Default <code>msg</code> <code>BaseMessage</code> <p>The LangChain message to convert.</p> required <code>role</code> <code>Optional[str]</code> <p>Explicitly specify the role to use. If None, role is detected from the message type. Defaults to None.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>Message</code> <code>Message</code> <p>A neurotrace Message with: - role determined by message type or override - content from the original message</p> Example <p>lc_msg = HumanMessage(content=\"Hello\") msg = from_langchain_message(lc_msg) print(msg.role)  # \"user\" print(msg.content)  # \"Hello\"</p> Source code in <code>neurotrace/core/adapters/langchain_adapter.py</code> <pre><code>def from_langchain_message(msg: BaseMessage, role: Optional[str] = None) -&gt; Message:\n    \"\"\"\n    Convert a LangChain message to a neurotrace Message.\n\n    This function transforms a LangChain message into neurotrace's Message format,\n    with automatic role detection based on the message type or an optional\n    explicit role override.\n\n    Args:\n        msg (BaseMessage): The LangChain message to convert.\n        role (Optional[str], optional): Explicitly specify the role to use.\n            If None, role is detected from the message type. Defaults to None.\n\n    Returns:\n        Message: A neurotrace Message with:\n            - role determined by message type or override\n            - content from the original message\n\n    Example:\n        &gt;&gt;&gt; lc_msg = HumanMessage(content=\"Hello\")\n        &gt;&gt;&gt; msg = from_langchain_message(lc_msg)\n        &gt;&gt;&gt; print(msg.role)  # \"user\"\n        &gt;&gt;&gt; print(msg.content)  # \"Hello\"\n    \"\"\"\n    detected_role = (\n        role if role else\n        \"human\" if isinstance(msg, HumanMessage) else\n        \"ai\" if isinstance(msg, AIMessage) else\n        \"system\"\n    )\n\n    role_literal = cast(Literal[\"user\", \"ai\", \"system\"], detected_role)\n    return Message(\n        role=role_literal,\n        content=msg.content\n    )\n</code></pre>"},{"location":"reference/documentation/core/adapters/vector_db_adapter/","title":"<code>neurotrace.core.adapters.vector_db_adapter</code>","text":""},{"location":"reference/documentation/core/adapters/vector_db_adapter/#neurotrace.core.adapters.vector_db_adapter","title":"<code>neurotrace.core.adapters.vector_db_adapter</code>","text":"<p>Vector Database Adapter Module.</p> <p>This module provides adapter functions for converting between neurotrace's internal message format and vector database record format. It handles the serialization of Message objects into a format suitable for vector database storage and retrieval.</p>"},{"location":"reference/documentation/core/adapters/vector_db_adapter/#neurotrace.core.adapters.vector_db_adapter.to_vector_record","title":"<code>to_vector_record(msg)</code>","text":"<p>Converts a Message object to a vector database record format.</p> <p>This function transforms a neurotrace Message instance into a dictionary format suitable for storage in a vector database. It extracts essential fields including the message ID, content text, embedding vector, and all associated metadata.</p> <p>Parameters:</p> Name Type Description Default <code>msg</code> <code>Message</code> <p>The Message object to convert.</p> required <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Dict[str, Any]: A dictionary containing: - id: The message's unique identifier - text: The message content - embedding: The message's vector embedding - metadata: All additional metadata as a dictionary</p> Example <p>message = Message(id=\"123\", content=\"Hello\", metadata=MessageMetadata(...)) record = to_vector_record(message) print(record) {     'id': '123',     'text': 'Hello',     'embedding': [...],     'metadata': {...} }</p> Source code in <code>neurotrace/core/adapters/vector_db_adapter.py</code> <pre><code>def to_vector_record(msg: Message) -&gt; Dict[str, Any]:\n    \"\"\"\n    Converts a Message object to a vector database record format.\n\n    This function transforms a neurotrace Message instance into a dictionary format\n    suitable for storage in a vector database. It extracts essential fields including\n    the message ID, content text, embedding vector, and all associated metadata.\n\n    Args:\n        msg (Message): The Message object to convert.\n\n    Returns:\n        Dict[str, Any]: A dictionary containing:\n            - id: The message's unique identifier\n            - text: The message content\n            - embedding: The message's vector embedding\n            - metadata: All additional metadata as a dictionary\n\n    Example:\n        &gt;&gt;&gt; message = Message(id=\"123\", content=\"Hello\", metadata=MessageMetadata(...))\n        &gt;&gt;&gt; record = to_vector_record(message)\n        &gt;&gt;&gt; print(record)\n        {\n            'id': '123',\n            'text': 'Hello',\n            'embedding': [...],\n            'metadata': {...}\n        }\n    \"\"\"\n    return {\n        \"id\": msg.id,\n        \"text\": msg.content,\n        \"embedding\": msg.metadata.embedding,\n        \"metadata\": msg.metadata.model_dump()\n    }\n</code></pre>"},{"location":"reference/documentation/core/hippocampus/ltm/","title":"<code>neurotrace.core.hippocampus.ltm</code>","text":""},{"location":"reference/documentation/core/hippocampus/ltm/#neurotrace.core.hippocampus.ltm","title":"<code>neurotrace.core.hippocampus.ltm</code>","text":""},{"location":"reference/documentation/core/hippocampus/ltm/#neurotrace.core.hippocampus.ltm.LongTermMemory","title":"<code>LongTermMemory</code>","text":"<p>               Bases: <code>ABC</code></p> Source code in <code>neurotrace/core/hippocampus/ltm.py</code> <pre><code>class LongTermMemory(ABC):\n    @abstractmethod\n    def add_message(self, message: Message) -&gt; None:\n        \"\"\"\n        Store a message in long-term memory.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def add_user_message(self, content: str) -&gt; None:\n        pass\n\n    @abstractmethod\n    def add_ai_message(self, content: str) -&gt; None:\n        pass\n\n    @abstractmethod\n    def get_messages(self, session_id: str) -&gt; List[Message]:\n        \"\"\"\n        Retrieve all messages for a given session ID.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def clear(self, session_id: str) -&gt; None:\n        \"\"\"\n        Clear messages for a given session.\n        \"\"\"\n        pass\n</code></pre>"},{"location":"reference/documentation/core/hippocampus/ltm/#neurotrace.core.hippocampus.ltm.LongTermMemory.add_message","title":"<code>add_message(message)</code>  <code>abstractmethod</code>","text":"<p>Store a message in long-term memory.</p> Source code in <code>neurotrace/core/hippocampus/ltm.py</code> <pre><code>@abstractmethod\ndef add_message(self, message: Message) -&gt; None:\n    \"\"\"\n    Store a message in long-term memory.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"reference/documentation/core/hippocampus/ltm/#neurotrace.core.hippocampus.ltm.LongTermMemory.clear","title":"<code>clear(session_id)</code>  <code>abstractmethod</code>","text":"<p>Clear messages for a given session.</p> Source code in <code>neurotrace/core/hippocampus/ltm.py</code> <pre><code>@abstractmethod\ndef clear(self, session_id: str) -&gt; None:\n    \"\"\"\n    Clear messages for a given session.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"reference/documentation/core/hippocampus/ltm/#neurotrace.core.hippocampus.ltm.LongTermMemory.get_messages","title":"<code>get_messages(session_id)</code>  <code>abstractmethod</code>","text":"<p>Retrieve all messages for a given session ID.</p> Source code in <code>neurotrace/core/hippocampus/ltm.py</code> <pre><code>@abstractmethod\ndef get_messages(self, session_id: str) -&gt; List[Message]:\n    \"\"\"\n    Retrieve all messages for a given session ID.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"reference/documentation/core/hippocampus/stm/","title":"<code>neurotrace.core.hippocampus.stm</code>","text":""},{"location":"reference/documentation/core/hippocampus/stm/#neurotrace.core.hippocampus.stm","title":"<code>neurotrace.core.hippocampus.stm</code>","text":""}]}